Fino a questo momento trattando il tema della memoria virtuale abbiamo assunto che le diverse parti della memoria centrale siano uguali, o almeno che vi si potesse accedere nello stesso modo. Su sistemi con accesso non uniforme alla memoria (numa) dotati di più cpu (Paragrafo 1.3.2) non è così. Su questi sistemi una determinata cpu può accedere ad alcune sezioni della memoria principale più velocemente di quanto possa accedere ad altre. Queste differenze di prestazioni sono causate dal modo in cui cpu e memoria sono interconnesse all’interno del sistema. 
Un sistema di questo tipo è costituito da più cpu, ciascuna con la propria memoria locale 
![[Pasted image 20221214173032.png]]
le cpu sono organizzate utilizzando un’interconnessione di sistema condivisa e, come ci si potrebbe aspettare, una cpu può accedere più velocemente alla propria memoria locale rispetto alla memoria locale di un’altra cpu. I sistemi numa sono, senza eccezioni, più lenti dei sistemi in cui tutti gli accessi alla memoria principale sono trattati allo stesso modo. Tuttavia, come descritto nel Paragrafo 1.3.2, questi sistemi possono ospitare diverse cpu e raggiungere quindi livelli maggiori di throughput e parallelismo.

Le decisioni su quali frame di pagina memorizzare in quale posizione possono condizionare in modo significativo le prestazioni nei sistemi numa.
Se, in sistemi del genere, consideriamo uniforme la memoria, i processori potrebbero dover aspettare molto più a lungo per accedere alla memoria rispetto al caso in cui gli algoritmi di allocazione della memoria siano modificati per tenere in conto il numa.
Il loro obiettivo è quello di disporre di frame di memoria allocati “il più vicino possibile” alla cpu su cui è in esecuzione il processo (per “vicino” intendiamo “con latenza minima”, ovvero, di solito, sulla stessa scheda della cpu). Pertanto, quando un processo incorre in un page fault, un sistema di memoria virtuale conscio del numa assegna a quel processo un frame il più vicino possibile alla cpu su cui è in esecuzione. Per tenere in considerazione numa, lo scheduler deve tenere traccia dell’ultima cpu su cui è stato eseguito ciascun processo. Se lo scheduler tenta di schedulare ciascun processo sulla cpu precedente e il sistema di gestione della memoria virtuale tenta di allocare i frame per il processo vicino alla cpu su cui il processo viene schedulato, si otterrà un incremento di cache hit e una diminuzione del tempo di accesso alla memoria.